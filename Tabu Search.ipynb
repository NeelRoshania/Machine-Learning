{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabu Search\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach\n",
    "    - The aim of this script is to calculate VIF and determine which features to consider for model training\n",
    "    - No extensive cleaning, outlier, or trend outlier consideration will be done\n",
    "        - The focus is VIF, not neccesarily model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interactive\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "import random as rand\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take original feature list, and replace one feature with a random other number not in that list\n",
    "def get_neighbor_random_insert_greedy(initial_features, potential_features):\n",
    "    \n",
    "    # Generate a random feature from the potential features list not in the initial features list\n",
    "    rand_feature = potential_features[rand.randint(0, len(potential_features)-1)]\n",
    "    while True:\n",
    "        if rand_feature in initial_features:\n",
    "            rand_feature = potential_features[rand.randint(0, len(potential_features)-1)]\n",
    "        else:\n",
    "            # If not in initial_features, select random position to insert feature\n",
    "            rand_pos = rand.randint(0, len(initial_features)-1)\n",
    "            initial_features[rand_pos] = rand_feature\n",
    "            break\n",
    "    return initial_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_optimization = pd.read_csv(\"df_pre_transform.csv\")\n",
    "df_optimization = df_optimization.drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "# preparing response variable data\n",
    "target = df_optimization.loc[:, 'REVENUE']\n",
    "all_features = df_optimization.loc[:, df_optimization.columns.isin(['REVENUE']) == False]\n",
    "\n",
    "# preparing training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            all_features,\n",
    "            target,\n",
    "            test_size = 0.25,\n",
    "            random_state = 222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "train = X_train\n",
    "train_score = []\n",
    "test_score = []\n",
    "sig_features = []\n",
    "model_type = []\n",
    "\n",
    "# p-value interations\n",
    "for i in range(0, 5, 1):\n",
    "    \n",
    "    # Find good p-values from OLS\n",
    "    model = sm.OLS(y_train, train).fit()\n",
    "    significant_features = list(model.pvalues[model.pvalues < 0.05].index.values)\n",
    "    \n",
    "    # Test and train with scikit-learn\n",
    "    lr = LinearRegression().fit(X_train.loc[:, significant_features], y_train)\n",
    "\n",
    "    lr_train_score = lr.score(X_train.loc[:, significant_features], y_train).round(4)\n",
    "    lr_test_score = lr.score(X_test.loc[:, significant_features], y_test).round(4)\n",
    "\n",
    "    # storing data\n",
    "    train_score.append(lr_train_score)\n",
    "    test_score.append(lr_test_score)\n",
    "    sig_features.append(significant_features)\n",
    "    model_type.append(\"LR\")\n",
    "    # train = X_train.loc[:, model.pvalues[model.pvalues < 0.05].index.values]\n",
    "\n",
    "model_performance = pd.DataFrame(\n",
    "    {\n",
    "        \"model_type\": model_type, \n",
    "        \"train_score\": train_score, \n",
    "        \"test_score\": test_score, \n",
    "        \"features\": sig_features\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.6798</td>\n",
       "      <td>0.6098</td>\n",
       "      <td>[TOTAL_MEALS_ORDERED, UNIQUE_MEALS_PURCH, CUST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.6798</td>\n",
       "      <td>0.6098</td>\n",
       "      <td>[TOTAL_MEALS_ORDERED, UNIQUE_MEALS_PURCH, CUST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.6798</td>\n",
       "      <td>0.6098</td>\n",
       "      <td>[TOTAL_MEALS_ORDERED, UNIQUE_MEALS_PURCH, CUST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.6798</td>\n",
       "      <td>0.6098</td>\n",
       "      <td>[TOTAL_MEALS_ORDERED, UNIQUE_MEALS_PURCH, CUST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.6798</td>\n",
       "      <td>0.6098</td>\n",
       "      <td>[TOTAL_MEALS_ORDERED, UNIQUE_MEALS_PURCH, CUST...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_type  train_score  test_score  \\\n",
       "0         LR       0.6798      0.6098   \n",
       "1         LR       0.6798      0.6098   \n",
       "2         LR       0.6798      0.6098   \n",
       "3         LR       0.6798      0.6098   \n",
       "4         LR       0.6798      0.6098   \n",
       "\n",
       "                                            features  \n",
       "0  [TOTAL_MEALS_ORDERED, UNIQUE_MEALS_PURCH, CUST...  \n",
       "1  [TOTAL_MEALS_ORDERED, UNIQUE_MEALS_PURCH, CUST...  \n",
       "2  [TOTAL_MEALS_ORDERED, UNIQUE_MEALS_PURCH, CUST...  \n",
       "3  [TOTAL_MEALS_ORDERED, UNIQUE_MEALS_PURCH, CUST...  \n",
       "4  [TOTAL_MEALS_ORDERED, UNIQUE_MEALS_PURCH, CUST...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_val_features = model_performance.iloc[4, :].features\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Greedy search with p_value_ optimized columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setup greedy algorithm\n",
    "iterations = 1000\n",
    "max_score = 0\n",
    "best_train = []\n",
    "best_test = []\n",
    "best_features = []\n",
    "\n",
    "# first iteration of p-value features\n",
    "features_considered = p_val_features\n",
    "\n",
    "# regress on features specific to p-values\n",
    "X_tr = X_train.loc[:, features_considered]\n",
    "X_te = X_test.loc[:, features_considered]\n",
    "\n",
    "# train test score\n",
    "lr = LinearRegression().fit(X_tr, y_train)\n",
    "train_score = lr.score(X_tr, y_train)\n",
    "test_score = lr.score(X_te, y_test)\n",
    "\n",
    "# max criteria\n",
    "if test_score > max_score:\n",
    "    max_score = test_score\n",
    "    best_train.append(train_score)\n",
    "    best_test.append(max_score)\n",
    "#     print(round(max_score, 4))\n",
    "    best_features.append(features_considered)\n",
    "        \n",
    "for i in range(0, iterations, 1):\n",
    "    \n",
    "    # Generate a random greedy neighbor\n",
    "    initial_greedy_random_neighbor_index = get_feature_index_locations(all_features, p_val_features)\n",
    "    potential_other_greedy_features = get_potential_features(all_features, initial_greedy_random_neighbor_index)\n",
    "    features_considered = get_neighbor_random_insert_greedy(initial_greedy_random_neighbor_index, potential_other_greedy_features)\n",
    "\n",
    "    # regress on features specific to p-values\n",
    "    X_tr = X_train.iloc[:, features_considered]\n",
    "    X_te = X_test.iloc[:, features_considered]\n",
    "    \n",
    "    # train test score\n",
    "    lr = LinearRegression().fit(X_tr, y_train)\n",
    "    train_score = lr.score(X_tr, y_train)\n",
    "    test_score = lr.score(X_te, y_test)\n",
    "    \n",
    "    # max criteria\n",
    "    if test_score > max_score:\n",
    "        max_score = test_score\n",
    "        best_train.append(train_score)\n",
    "        best_test.append(max_score)\n",
    "#         print(round(max_score, 4))\n",
    "        best_features.append(features_considered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value features - Test: 0.6097774098551809\n",
      "Greedy search with p-value features: 0.6154690025645886\n"
     ]
    }
   ],
   "source": [
    "print(\"p-value features - Test: {}\".format(\n",
    "    LinearRegression()\\\n",
    "    .fit(X_train.loc[:, p_val_features], y_train)\\\n",
    "    .score(X_test.loc[:, p_val_features], y_test)))\n",
    "\n",
    "print(\"Greedy search with p-value features: {}\".format(\n",
    "    LinearRegression()\\\n",
    "    .fit(X_train.iloc[:, best_features[-1]], y_train)\\\n",
    "    .score(X_test.iloc[:, best_features[-1]], y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabu Search Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabu Search implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1,3] in [[1,2], [4, 5]]\n",
    "\n",
    "# get list of neighbors that are not considered for optimization\n",
    "def get_neighbors(initial_features, potential_features):\n",
    "    # initialize data structures\n",
    "    current_neighbor = []\n",
    "    neighborhood_list = []\n",
    "    swap_list = [] # []\n",
    "    \n",
    "    # decide a random potential feature\n",
    "    feature_index_swap = rand.randint(0, len(potential_features)-1)\n",
    "    \n",
    "    # generate neighborhood swaps\n",
    "    for i in range(0, len(initial_features), 1):\n",
    "        \n",
    "        # Shadow copy of initial features\n",
    "        current_neighbor = initial_features[:]\n",
    "        current_neighbor[i] = potential_features[feature_index_swap]\n",
    "        neighborhood_list.append(current_neighbor)\n",
    "        swap_list.append([i, feature_index_swap])\n",
    "        \n",
    "    return neighborhood_list, swap_list\n",
    "        \n",
    "\n",
    "def get_potential_features(features_all, initial_best_neighbor_index):\n",
    "    potential_index = []\n",
    "    for i in features_all:\n",
    "        if features_all.columns.get_loc(i) not in initial_best_neighbor_index:\n",
    "            potential_index.append(features_all.columns.get_loc(i))\n",
    "    return potential_index\n",
    "\n",
    "def get_feature_index_locations(df, column_features):\n",
    "    feature_indexes = []\n",
    "    for i in column_features:\n",
    "        if i in df.columns:\n",
    "            feature_indexes.append(df.columns.get_loc(i))\n",
    "    return feature_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total iterations: 1000\n"
     ]
    }
   ],
   "source": [
    "algorithm_comp_count = 0\n",
    "\n",
    "# algorithm setup\n",
    "initial_best_neighbor_index = get_feature_index_locations(all_features, p_val_features)\n",
    "potential_other_features_index = get_potential_features(all_features, initial_best_neighbor_index)\n",
    "best_solution_index = initial_best_neighbor_index[:]\n",
    "lr = LinearRegression()\n",
    "tabu_list_index = []\n",
    "best_neighbor_score = 0 \n",
    "best_neighbor_features = []\n",
    "best_neighbor_score_l = []\n",
    "best_neighbor_features_l = []\n",
    "\n",
    "best_global_score = 0\n",
    "best_global_score_l = []\n",
    "best_global_features_l = []\n",
    "\n",
    "# algorithm parameter setup\n",
    "tabu_tenure = 5\n",
    "aspire_iteration = 1000\n",
    "\n",
    "for i in range(0, aspire_iteration, 1):\n",
    "    algorithm_comp_count += 1\n",
    "    \n",
    "    # generate neighborhood space\n",
    "    neighbors, neighbor_swaps = get_neighbors(initial_best_neighbor_index, potential_other_features_index)\n",
    "    \n",
    "    for i in range(0, len(neighbors), 1):\n",
    "\n",
    "        # In this case, a feature swap of 1 and 5 is the same as 5 and 1\n",
    "        neighbor_to_swap = neighbor_swaps[i]\n",
    "        alt_neighbor_to_swap = neighbor_to_swap.reverse()\n",
    "\n",
    "        # check tabu list\n",
    "        if (neighbor_to_swap) not in tabu_list_index:\n",
    "            if (alt_neighbor_to_swap) not in tabu_list_index:\n",
    "                # Calculate algorithm score\n",
    "                lr_fit = lr.fit(X_train.iloc[:, neighbors[i]], y_train)\n",
    "                lr_train_score = lr.score(X_train.iloc[:, neighbors[i]], y_train).round(4)\n",
    "                lr_test_score = lr.score(X_test.iloc[:, neighbors[i]], y_test).round(4)\n",
    "\n",
    "                # if neighbor score is greater then best score, update initial_best_neighbor_index\n",
    "                if lr_test_score > best_neighbor_score:\n",
    "                    best_neighbor_score = lr_test_score\n",
    "                    best_neighbor_features = neighbors[i]\n",
    "                    best_swap = neighbor_to_swap\n",
    "                    initial_best_neighbor_index = neighbors[i]\n",
    "\n",
    "    # Update Tabu List, best neighbor and corresponding features\n",
    "    if len(tabu_list_index) < 10:\n",
    "        tabu_list_index.append(best_swap)\n",
    "    else:\n",
    "        # if tabu list is greater then tabu_tenure, then push all values up list by 1 and rid that last entry\n",
    "        tabu_list_index[1:] = tabu_list_index[0:-1]\n",
    "        tabu_list_index[0] = best_swap\n",
    "        \n",
    "#     print(tabu_list_index)\n",
    "    \n",
    "    best_neighbor_score_l.append(best_neighbor_score)\n",
    "    best_neighbor_features_l.append(best_neighbor_features)\n",
    "    \n",
    "    # Update global maximum scores\n",
    "    if best_neighbor_score > best_global_score:\n",
    "        best_global_score = best_neighbor_score\n",
    "        best_global_score_l.append(best_neighbor_score)\n",
    "        best_global_features_l.append(best_neighbor_features)\n",
    "        aspire_iteration = 1\n",
    "    else:\n",
    "        aspire_iteration += 1\n",
    "        # print(\"TS aspired..\")\n",
    "        \n",
    "    # Reset neighborhood scores\n",
    "    best_neighbor_score = 0\n",
    "    lr_train_score = 0\n",
    "    lr_test_score = 0\n",
    "    \n",
    "print(\"Total iterations: {}\".format(algorithm_comp_count))\n",
    "# print(\"\")\n",
    "# print(best_global_score_l[-1])\n",
    "# print(best_global_features_l[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value features - Test: 0.6097774098551809\n",
      "Tabu search with p-value features: 0.6215748156564418\n"
     ]
    }
   ],
   "source": [
    "print(\"p-value features - Test: {}\".format(\n",
    "    LinearRegression()\\\n",
    "    .fit(X_train.loc[:, p_val_features], y_train)\\\n",
    "    .score(X_test.loc[:, p_val_features], y_test)))\n",
    "\n",
    "print(\"Tabu search with p-value features: {}\".format(\n",
    "    LinearRegression()\\\n",
    "    .fit(X_train.iloc[:, best_global_features_l[-1]], y_train)\\\n",
    "    .score(X_test.iloc[:, best_global_features_l[-1]], y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6216"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_global_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(best_global_features_l[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p_val_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
